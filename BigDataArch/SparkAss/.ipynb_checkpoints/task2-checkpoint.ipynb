{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\spark-3.1.1-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile \n",
    "pd.set_option(\"display.max_columns\",1000)\n",
    "\n",
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "findspark.init()\n",
    "#findspark.init('C:\\Spark\\spark-3.1.1-bin-hadoop2.7')\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark df\n",
    "In order to work with spark within python, we need to create a Spark Session. Here we call the app ' Project1 ' and we assign this to a python object named 'spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Project1').getOrCreate()#.master(\"local\") #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV to python df\n",
    "We pull in the flights.csv first as a pandas dataframe in python. Within python, we can do some basic cleaning and manipulation for the tasks ahead.\n",
    "\n",
    "*important*: \n",
    "\n",
    "Here, in preparation for task 3, we create a column named 'DEP_HR' which is a string containing just the hour that the flight departed. We will use this as our y variable in our regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_CODE</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>DEP_HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N8974C</td>\n",
       "      <td>9E</td>\n",
       "      <td>AVL</td>\n",
       "      <td>Asheville, NC</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1658</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1758</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N922XJ</td>\n",
       "      <td>9E</td>\n",
       "      <td>JFK</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>RDU</td>\n",
       "      <td>Raleigh/Durham, NC</td>\n",
       "      <td>1122</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1255</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N326PQ</td>\n",
       "      <td>9E</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cleveland, OH</td>\n",
       "      <td>DTW</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>1334</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1417</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N135EV</td>\n",
       "      <td>9E</td>\n",
       "      <td>BHM</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1059</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1255</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N914XJ</td>\n",
       "      <td>9E</td>\n",
       "      <td>GTF</td>\n",
       "      <td>Great Falls, MT</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>1057</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1418</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N257NN</td>\n",
       "      <td>MQ</td>\n",
       "      <td>STL</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1220</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1327</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N855AE</td>\n",
       "      <td>MQ</td>\n",
       "      <td>LGA</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>CMH</td>\n",
       "      <td>Columbus, OH</td>\n",
       "      <td>1048</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1233</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N688AE</td>\n",
       "      <td>MQ</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>COU</td>\n",
       "      <td>Columbia, MO</td>\n",
       "      <td>2317</td>\n",
       "      <td>52.0</td>\n",
       "      <td>104</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N262NN</td>\n",
       "      <td>MQ</td>\n",
       "      <td>MSN</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>N228NN</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>LEX</td>\n",
       "      <td>Lexington, KY</td>\n",
       "      <td>1821</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2120</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FL_DATE TAIL_NUM CARRIER ORIGIN       ORIGIN_CITY_NAME DEST  \\\n",
       "0    2019-01-01   N8974C      9E    AVL          Asheville, NC  ATL   \n",
       "1    2019-01-01   N922XJ      9E    JFK           New York, NY  RDU   \n",
       "2    2019-01-01   N326PQ      9E    CLE          Cleveland, OH  DTW   \n",
       "3    2019-01-01   N135EV      9E    BHM         Birmingham, AL  ATL   \n",
       "4    2019-01-01   N914XJ      9E    GTF        Great Falls, MT  MSP   \n",
       "..          ...      ...     ...    ...                    ...  ...   \n",
       "995  2019-01-01   N257NN      MQ    STL          St. Louis, MO  ORD   \n",
       "996  2019-01-01   N855AE      MQ    LGA           New York, NY  CMH   \n",
       "997  2019-01-01   N688AE      MQ    ORD            Chicago, IL  COU   \n",
       "998  2019-01-01   N262NN      MQ    MSN            Madison, WI  ORD   \n",
       "999  2019-01-01   N228NN      MQ    DFW  Dallas/Fort Worth, TX  LEX   \n",
       "\n",
       "         DEST_CITY_NAME DEP_TIME DEP_DELAY ARR_TIME ARR_DELAY CANCELLED  \\\n",
       "0           Atlanta, GA     1658      -7.0     1758     -22.0       0.0   \n",
       "1    Raleigh/Durham, NC     1122      -8.0     1255     -29.0       0.0   \n",
       "2           Detroit, MI     1334      -7.0     1417     -31.0       0.0   \n",
       "3           Atlanta, GA     1059      -1.0     1255      -8.0       0.0   \n",
       "4       Minneapolis, MN     1057      -3.0     1418     -17.0       0.0   \n",
       "..                  ...      ...       ...      ...       ...       ...   \n",
       "995         Chicago, IL     1220      14.0     1327      -7.0       0.0   \n",
       "996        Columbus, OH     1048     -12.0     1233     -34.0       0.0   \n",
       "997        Columbia, MO     2317      52.0      104      80.0       0.0   \n",
       "998         Chicago, IL        0       0.0        0       0.0       1.0   \n",
       "999       Lexington, KY     1821      36.0     2120      32.0       0.0   \n",
       "\n",
       "    CANCELLATION_CODE DIVERTED CARRIER_DELAY WEATHER_DELAY NAS_DELAY  \\\n",
       "0                   0      0.0           0.0           0.0       0.0   \n",
       "1                   0      0.0           0.0           0.0       0.0   \n",
       "2                   0      0.0           0.0           0.0       0.0   \n",
       "3                   0      0.0           0.0           0.0       0.0   \n",
       "4                   0      0.0           0.0           0.0       0.0   \n",
       "..                ...      ...           ...           ...       ...   \n",
       "995                 0      0.0           0.0           0.0       0.0   \n",
       "996                 0      0.0           0.0           0.0       0.0   \n",
       "997                 0      0.0           0.0           0.0      28.0   \n",
       "998                 B      0.0           0.0           0.0       0.0   \n",
       "999                 0      0.0          32.0           0.0       0.0   \n",
       "\n",
       "    SECURITY_DELAY LATE_AIRCRAFT_DELAY Unnamed: 19 DEP_HR  \n",
       "0              0.0                 0.0         0.0     16  \n",
       "1              0.0                 0.0         0.0     11  \n",
       "2              0.0                 0.0         0.0     13  \n",
       "3              0.0                 0.0         0.0     10  \n",
       "4              0.0                 0.0         0.0     10  \n",
       "..             ...                 ...         ...    ...  \n",
       "995            0.0                 0.0         0.0     12  \n",
       "996            0.0                 0.0         0.0     10  \n",
       "997            0.0                52.0         0.0     23  \n",
       "998            0.0                 0.0         0.0         \n",
       "999            0.0                 0.0         0.0     18  \n",
       "\n",
       "[1000 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('flights.csv.zip')\n",
    "df = df.fillna(0)\n",
    "df['DEP_TIME'] = df['DEP_TIME'].astype('int')\n",
    "df['DEP_HR'] = df['DEP_TIME'].astype('str').str[:-2] \n",
    "df['ARR_TIME'] = df['ARR_TIME'].astype('int')\n",
    "df = df.fillna(0)\n",
    "df = df.astype('str')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Schema\n",
    "for ease of loading into Spark, we make everything a string initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, IntegerType, DateType\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"FL_DATE\", StringType()),#, DateType()),\n",
    "    StructField(\"TAIL_NUM\", StringType()),\n",
    "    StructField(\"CARRIER\", StringType()),\n",
    "    StructField(\"ORIGIN\", StringType()),\n",
    "    StructField(\"ORIGIN_CITY_NAME\", StringType()),\n",
    "    StructField(\"DEST\", StringType()),\n",
    "    StructField(\"DEST_CITY_NAME\", StringType()),\n",
    "    StructField(\"DEP_TIME\", StringType()),\n",
    "    StructField(\"DEP_DELAY\", StringType()),#, DoubleType()),\n",
    "    StructField(\"ARR_TIME\", StringType()),\n",
    "    StructField(\"ARR_DELAY\", StringType()),#, DoubleType()),\n",
    "    StructField(\"CANCELLED\", StringType()),\n",
    "    StructField(\"CANCELLATION_CODE\", StringType()),\n",
    "    StructField(\"DIVERTED\", StringType()),\n",
    "    StructField(\"CARRIER_DELAY\", StringType()),\n",
    "    StructField(\"WEATHER_DELAY\", StringType()),\n",
    "    StructField(\"NAS_DELAY\", StringType()),\n",
    "    StructField(\"SECURITY_DELAY\", StringType()),\n",
    "    StructField(\"LATE_AIRCRAFT_DELAY\", StringType()),\n",
    "    StructField(\"Unnamed: 19\", StringType()),#, IntegerType())\n",
    "    StructField(\"DEP_HR\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark DF from pandas df\n",
    "Now we create a Spark dataframe from our pandas dataframe in python. We print the schema just to review it and verify that everything worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- TAIL_NUM: string (nullable = true)\n",
      " |-- CARRIER: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- ORIGIN_CITY_NAME: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- DEST_CITY_NAME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- Unnamed: 19: string (nullable = true)\n",
      " |-- DEP_HR: string (nullable = true)\n",
      "\n",
      "+----------+--------+-------+------+--------------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+-----------+------+\n",
      "|   FL_DATE|TAIL_NUM|CARRIER|ORIGIN|    ORIGIN_CITY_NAME|DEST|    DEST_CITY_NAME|DEP_TIME|DEP_DELAY|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 19|DEP_HR|\n",
      "+----------+--------+-------+------+--------------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+-----------+------+\n",
      "|2019-01-01|  N8974C|     9E|   AVL|       Asheville, NC| ATL|       Atlanta, GA|    1658|     -7.0|    1758|    -22.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    16|\n",
      "|2019-01-01|  N922XJ|     9E|   JFK|        New York, NY| RDU|Raleigh/Durham, NC|    1122|     -8.0|    1255|    -29.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    11|\n",
      "|2019-01-01|  N326PQ|     9E|   CLE|       Cleveland, OH| DTW|       Detroit, MI|    1334|     -7.0|    1417|    -31.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    13|\n",
      "|2019-01-01|  N135EV|     9E|   BHM|      Birmingham, AL| ATL|       Atlanta, GA|    1059|     -1.0|    1255|     -8.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    10|\n",
      "|2019-01-01|  N914XJ|     9E|   GTF|     Great Falls, MT| MSP|   Minneapolis, MN|    1057|     -3.0|    1418|    -17.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    10|\n",
      "|2019-01-01|  N924EV|     9E|   GRB|       Green Bay, WI| DTW|       Detroit, MI|     855|      0.0|    1125|     10.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|     8|\n",
      "|2019-01-01|  N195PQ|     9E|   AGS|         Augusta, GA| ATL|       Atlanta, GA|     800|     -5.0|     900|    -16.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|     8|\n",
      "|2019-01-01|  N319PQ|     9E|   CLT|       Charlotte, NC| JFK|      New York, NY|    1350|    -10.0|    1534|    -29.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    13|\n",
      "|2019-01-01|  N933XJ|     9E|   MEM|         Memphis, TN| MSP|   Minneapolis, MN|    1441|     -4.0|    1641|    -18.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    14|\n",
      "|2019-01-01|  N933XJ|     9E|   MSP|     Minneapolis, MN| MEM|       Memphis, TN|     847|     -4.0|    1114|     -6.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|     8|\n",
      "|2019-01-01|  N8886A|     9E|   ATL|         Atlanta, GA| AEX|    Alexandria, LA|    1856|     -5.0|    1931|    -20.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    18|\n",
      "|2019-01-01|  N302PQ|     9E|   AGS|         Augusta, GA| ATL|       Atlanta, GA|    1427|     -9.0|    1540|     -4.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    14|\n",
      "|2019-01-01|  N302PQ|     9E|   ATL|         Atlanta, GA| AGS|       Augusta, GA|    1259|     -6.0|    1343|    -18.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    12|\n",
      "|2019-01-01|  N272PQ|     9E|   CVG|      Cincinnati, OH| LGA|      New York, NY|     834|     -6.0|    1022|    -18.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|     8|\n",
      "|2019-01-01|  N292PQ|     9E|   RDU|  Raleigh/Durham, NC| MCO|       Orlando, FL|    1324|     -1.0|    1504|    -14.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    13|\n",
      "|2019-01-01|  N980EV|     9E|   GSO|Greensboro/High P...| LGA|      New York, NY|    1155|     -5.0|    1340|      3.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    11|\n",
      "|2019-01-01|  N326PQ|     9E|   BIS| Bismarck/Mandan, ND| MSP|   Minneapolis, MN|     809|    124.0|     933|    109.0|      0.0|                0|     0.0|        109.0|          0.0|      0.0|           0.0|                0.0|        0.0|     8|\n",
      "|2019-01-01|  N135EV|     9E|   ATL|         Atlanta, GA| AVL|     Asheville, NC|    1531|     -4.0|    1625|    -10.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    15|\n",
      "|2019-01-01|  N8976E|     9E|   LGA|        New York, NY| BTV|    Burlington, VT|    1756|     -4.0|    1913|     -7.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    17|\n",
      "|2019-01-01|  N925XJ|     9E|   PIT|      Pittsburgh, PA| JFK|      New York, NY|    1124|     -1.0|    1249|     -4.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|    11|\n",
      "+----------+--------+-------+------+--------------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create PySpark DataFrame from Pandas\n",
    "flts=spark.createDataFrame(df,schema=schema) \n",
    "flts.printSchema()\n",
    "flts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Delays from String to Doubles\n",
    "Finally, now that we have a Spark dataframe - we know that some variables need to be transformed into numerical values. So we convert the strings DEP_DELAY, ARR_DELAY and DEP_HR into Doubles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+------+--------------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+-----------+------+\n",
      "|   FL_DATE|TAIL_NUM|CARRIER|ORIGIN|    ORIGIN_CITY_NAME|DEST|    DEST_CITY_NAME|DEP_TIME|DEP_DELAY|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 19|DEP_HR|\n",
      "+----------+--------+-------+------+--------------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+-----------+------+\n",
      "|2019-01-01|  N8974C|     9E|   AVL|       Asheville, NC| ATL|       Atlanta, GA|    1658|     -7.0|    1758|    -22.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  16.0|\n",
      "|2019-01-01|  N922XJ|     9E|   JFK|        New York, NY| RDU|Raleigh/Durham, NC|    1122|     -8.0|    1255|    -29.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  11.0|\n",
      "|2019-01-01|  N326PQ|     9E|   CLE|       Cleveland, OH| DTW|       Detroit, MI|    1334|     -7.0|    1417|    -31.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  13.0|\n",
      "|2019-01-01|  N135EV|     9E|   BHM|      Birmingham, AL| ATL|       Atlanta, GA|    1059|     -1.0|    1255|     -8.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  10.0|\n",
      "|2019-01-01|  N914XJ|     9E|   GTF|     Great Falls, MT| MSP|   Minneapolis, MN|    1057|     -3.0|    1418|    -17.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  10.0|\n",
      "|2019-01-01|  N924EV|     9E|   GRB|       Green Bay, WI| DTW|       Detroit, MI|     855|      0.0|    1125|     10.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|   8.0|\n",
      "|2019-01-01|  N195PQ|     9E|   AGS|         Augusta, GA| ATL|       Atlanta, GA|     800|     -5.0|     900|    -16.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|   8.0|\n",
      "|2019-01-01|  N319PQ|     9E|   CLT|       Charlotte, NC| JFK|      New York, NY|    1350|    -10.0|    1534|    -29.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  13.0|\n",
      "|2019-01-01|  N933XJ|     9E|   MEM|         Memphis, TN| MSP|   Minneapolis, MN|    1441|     -4.0|    1641|    -18.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  14.0|\n",
      "|2019-01-01|  N933XJ|     9E|   MSP|     Minneapolis, MN| MEM|       Memphis, TN|     847|     -4.0|    1114|     -6.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|   8.0|\n",
      "|2019-01-01|  N8886A|     9E|   ATL|         Atlanta, GA| AEX|    Alexandria, LA|    1856|     -5.0|    1931|    -20.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  18.0|\n",
      "|2019-01-01|  N302PQ|     9E|   AGS|         Augusta, GA| ATL|       Atlanta, GA|    1427|     -9.0|    1540|     -4.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  14.0|\n",
      "|2019-01-01|  N302PQ|     9E|   ATL|         Atlanta, GA| AGS|       Augusta, GA|    1259|     -6.0|    1343|    -18.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  12.0|\n",
      "|2019-01-01|  N272PQ|     9E|   CVG|      Cincinnati, OH| LGA|      New York, NY|     834|     -6.0|    1022|    -18.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|   8.0|\n",
      "|2019-01-01|  N292PQ|     9E|   RDU|  Raleigh/Durham, NC| MCO|       Orlando, FL|    1324|     -1.0|    1504|    -14.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  13.0|\n",
      "|2019-01-01|  N980EV|     9E|   GSO|Greensboro/High P...| LGA|      New York, NY|    1155|     -5.0|    1340|      3.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  11.0|\n",
      "|2019-01-01|  N326PQ|     9E|   BIS| Bismarck/Mandan, ND| MSP|   Minneapolis, MN|     809|    124.0|     933|    109.0|      0.0|                0|     0.0|        109.0|          0.0|      0.0|           0.0|                0.0|        0.0|   8.0|\n",
      "|2019-01-01|  N135EV|     9E|   ATL|         Atlanta, GA| AVL|     Asheville, NC|    1531|     -4.0|    1625|    -10.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  15.0|\n",
      "|2019-01-01|  N8976E|     9E|   LGA|        New York, NY| BTV|    Burlington, VT|    1756|     -4.0|    1913|     -7.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  17.0|\n",
      "|2019-01-01|  N925XJ|     9E|   PIT|      Pittsburgh, PA| JFK|      New York, NY|    1124|     -1.0|    1249|     -4.0|      0.0|                0|     0.0|          0.0|          0.0|      0.0|           0.0|                0.0|        0.0|  11.0|\n",
      "+----------+--------+-------+------+--------------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "StructType(List(StructField(FL_DATE,StringType,true),StructField(TAIL_NUM,StringType,true),StructField(CARRIER,StringType,true),StructField(ORIGIN,StringType,true),StructField(ORIGIN_CITY_NAME,StringType,true),StructField(DEST,StringType,true),StructField(DEST_CITY_NAME,StringType,true),StructField(DEP_TIME,StringType,true),StructField(DEP_DELAY,DoubleType,true),StructField(ARR_TIME,StringType,true),StructField(ARR_DELAY,DoubleType,true),StructField(CANCELLED,StringType,true),StructField(CANCELLATION_CODE,StringType,true),StructField(DIVERTED,StringType,true),StructField(CARRIER_DELAY,StringType,true),StructField(WEATHER_DELAY,StringType,true),StructField(NAS_DELAY,StringType,true),StructField(SECURITY_DELAY,StringType,true),StructField(LATE_AIRCRAFT_DELAY,StringType,true),StructField(Unnamed: 19,StringType,true),StructField(DEP_HR,DoubleType,true)))\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "flts = flts.withColumn(\"DEP_DELAY\", flts['DEP_DELAY'].cast(DoubleType())).withColumn('ARR_DELAY', flts['ARR_DELAY'].cast(DoubleType())).withColumn(\"DEP_HR\", flts['DEP_HR'].cast(DoubleType()))\n",
    "flts.show()\n",
    "print(flts.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as the final step for the data preparation, we create a temporary SQL table named \"flights\". We will use this in the tasks to more easily manipulate the data in a \"SQL-esque\" environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flts.createOrReplaceTempView(\"flights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 [35 points]\n",
    "For this task you continue to work with SparkSQL. The objective is to create reports on the\n",
    "average and median departure delays of \n",
    "- (a) all the airports\n",
    "- (b) all the airways in the dataset\n",
    "You should give four reports: \n",
    "- two for the airports (average/median delays)\n",
    "- two for the airways (average/median delays)\n",
    "\n",
    "Each report is a CSV file containing one line for each airport/airway \n",
    "and the lines of each file should be ordered (in descending order) based on the\n",
    "corresponding criterion (average/median delay). \n",
    "No header files are required for these files.\n",
    "An extra instruction you have from your supervisor is that you should take care of some data\n",
    "outliers: you should not consider in your analysis any airports/airways that have extremely\n",
    "low number of flights; the criterion is that any airport/airway belonging in the lowest 1%\n",
    "percentile, regarding the number of flights, should be omitted. Your deliverables for this task\n",
    "are the following:\n",
    "- A Python file (named “task2.py”) containing the code to produce the reports.\n",
    "- A report (named “task2.pdf”) explaining the basic intuition of your code.\n",
    "- The four report files (named “task2-ap-avg.csv”, “task2-ap-med.csv”, “task2-awavg.csv”, and “task2-aw-med.csv”) having the determined file structure. Please\n",
    "restrict the number of lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airports Departure Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average\n",
    "In this first query, we are simpy trying to get the lowest 1% percentile. We then take that value and use it as a parameter in the second query.\n",
    "\n",
    "Additionally, we limit the records to 100 per the instructions so we do not create too much data in the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    ORIGIN\n",
    "    , avg(DEP_DELAY)\n",
    "    FROM flights \n",
    "    group by ORIGIN\n",
    "    order by 2 desc\n",
    "    limit 100;\n",
    "    \"\"\")\n",
    "perc = query.stat.approxQuantile(\"avg(DEP_DELAY)\",[0.01],0.0)\n",
    "perc = int(perc[0])\n",
    "perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create a CSV file in our directory limited to 100 rows and headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|ORIGIN|    avg(DEP_DELAY)|\n",
      "+------+------------------+\n",
      "|   TVC|             209.0|\n",
      "|   VPS|             131.5|\n",
      "|   BIS|             124.0|\n",
      "|   PWM|              87.5|\n",
      "|   BIL|              59.0|\n",
      "|   GTF|              49.0|\n",
      "|   RFD|              46.0|\n",
      "|   TUS|              36.0|\n",
      "|   CMH|34.285714285714285|\n",
      "|   MSN|              34.0|\n",
      "|   XNA|              34.0|\n",
      "|   ELP|              31.5|\n",
      "|   FWA|              31.0|\n",
      "|   BLI|30.666666666666668|\n",
      "|   ABQ|              29.0|\n",
      "|   KOA|              28.0|\n",
      "|   ALB|              27.0|\n",
      "|   AZA|26.333333333333332|\n",
      "|   ONT|              25.0|\n",
      "|   MCI|24.666666666666668|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = spark.sql(\"\"\"\n",
    "    SELECT ORIGIN\n",
    "    , avg(DEP_DELAY)\n",
    "    FROM flights \n",
    "    group by ORIGIN\n",
    "    having avg(DEP_DELAY) > {}\n",
    "    order by 2 desc\n",
    "    limit 100;\n",
    "    \"\"\".format(perc))\n",
    "query.repartition(1).write.csv(\"task2-ap-avg.csv\", sep=',',header=None)\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median\n",
    "In this first query, we are simpy trying to get the lowest 1% percentile. We then take that value and use it as a parameter in the second query. We continue this pattern for the Airway Departure Delays and in the interest of brevity, I will not duplicate this comment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = spark.sql(\"\"\"\n",
    "    SELECT ORIGIN\n",
    "    ,percentile(DEP_DELAY, 0.5) as med\n",
    "    FROM flights \n",
    "    group by ORIGIN\n",
    "    order by 2 desc\n",
    "    limit 100;\n",
    "    \"\"\")\n",
    "perc = query.stat.approxQuantile(\"med\",[0.01],0.0)\n",
    "perc = int(perc[0])\n",
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|ORIGIN|  med|\n",
      "+------+-----+\n",
      "|   TVC|209.0|\n",
      "|   VPS|131.5|\n",
      "|   BIS|124.0|\n",
      "|   PWM| 87.5|\n",
      "|   BIL| 59.0|\n",
      "|   GTF| 49.0|\n",
      "|   RFD| 46.0|\n",
      "|   MSN| 34.0|\n",
      "|   XNA| 34.0|\n",
      "|   ELP| 31.5|\n",
      "|   FWA| 31.0|\n",
      "|   ABQ| 29.0|\n",
      "|   KOA| 28.0|\n",
      "|   ALB| 27.0|\n",
      "|   ONT| 25.0|\n",
      "|   SFB| 23.0|\n",
      "|   COU| 23.0|\n",
      "|   AZA| 21.0|\n",
      "|   BQN| 21.0|\n",
      "|   MSO| 21.0|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = spark.sql(\"\"\"\n",
    "    SELECT ORIGIN\n",
    "    ,percentile(DEP_DELAY, 0.5) as med\n",
    "    FROM flights \n",
    "    group by ORIGIN\n",
    "    having med > {}\n",
    "    order by 2 desc\n",
    "    limit 100;\n",
    "    \"\"\".format(perc))\n",
    "query.repartition(1).write.csv(\"task2-ap-med.csv\", sep=',',header=None)\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airways Departure Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    CARRIER\n",
    "    , avg(DEP_DELAY)\n",
    "    FROM flights \n",
    "    group by CARRIER\n",
    "    order by 2 desc\n",
    "    limit 100;\n",
    "    \"\"\")\n",
    "perc = query.stat.approxQuantile(\"avg(DEP_DELAY)\",[0.01],0.0)\n",
    "perc = int(perc[0])\n",
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|CARRIER|    avg(DEP_DELAY)|\n",
      "+-------+------------------+\n",
      "|     G4|11.942857142857143|\n",
      "|     MQ|  7.91044776119403|\n",
      "|     AA| 7.249578414839798|\n",
      "|     NK| 4.504273504273504|\n",
      "|     9E|2.6405228758169934|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    CARRIER\n",
    "    , avg(DEP_DELAY)\n",
    "    FROM flights \n",
    "    group by CARRIER\n",
    "    having avg(DEP_DELAY) > {}\n",
    "    order by 2 desc\n",
    "    limit 100;\n",
    "    \"\"\".format(perc))\n",
    "query.repartition(1).write.csv(\"task2-aw-avg.csv\", sep=',',header=None)\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    CARRIER\n",
    "    ,percentile(DEP_DELAY, 0.5) as med\n",
    "    FROM flights \n",
    "    group by CARRIER\n",
    "    order by 2 desc\n",
    "    limit 100;\n",
    "    \"\"\")\n",
    "perc = query.stat.approxQuantile(\"med\",[0.01],0.0)\n",
    "perc = int(perc[0])\n",
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|CARRIER| med|\n",
      "+-------+----+\n",
      "|     MQ| 0.0|\n",
      "|     AA|-1.0|\n",
      "|     G4|-1.5|\n",
      "|     NK|-3.0|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "    CARRIER\n",
    "    ,percentile(DEP_DELAY, 0.5) as med\n",
    "    FROM flights \n",
    "    group by CARRIER\n",
    "    having med > {}\n",
    "    order by 2 desc\n",
    "    limit 100;\n",
    "    \"\"\".format(perc))\n",
    "query.repartition(1).write.csv(\"task2-aw-med.csv\", sep=',',header=None)\n",
    "query.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
