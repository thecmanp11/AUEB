{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"b_keras_text_cnn.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"fJ1dXvteYNrM"},"source":["# Big Data Content Analytics - AUEB\n","\n","## Introduction to Convolutional Networks for Text Classification\n","\n","* Lab Assistant: George Perakis\n","* Email: gperakis[at]aeub.gr | perakisgeorgios[at]gmail.com"]},{"cell_type":"markdown","metadata":{"id":"_qJjlK6NYNrO"},"source":["### Importing Modules"]},{"cell_type":"code","metadata":{"id":"Nd7ZGpeaYNrP"},"source":["import numpy as np\n","\n","from tensorflow.python import keras\n","\n","from tensorflow.python.keras.preprocessing import sequence\n","\n","from tensorflow.python.keras.models import Sequential\n","\n","from tensorflow.python.keras.layers import Dense, Dropout, Activation\n","from tensorflow.python.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D\n","\n","from tensorflow.python.keras.datasets import imdb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kTvO4nH1YNrT"},"source":["### Setting experiment hyperparameters"]},{"cell_type":"code","metadata":{"id":"I-1l1ntXYNrU"},"source":["# set parameters:\n","\n","max_features = 15_000 # total vocabulary size\n","\n","maxlen = 400 # maximum length of tokens to use for each review"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AgkJQR-aYNrY"},"source":["print('Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative).\\n\\nReviews have been preprocessed, and each review is encoded as a sequence \\nof word indexes (integers).\\n\\nFor convenience, words are indexed by overall frequency in the dataset,\\nso that for instance the integer \"3\" encodes the 3rd most frequent word in the data.\\n\\nThis allows for quick filtering operations such as: \"only consider the top 10,000 \\nmost common words, but eliminate the top 20 most common words\".\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DX3mm1lWYNrd"},"source":["print('Loading data...')\n","\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","# in case this fails, then you should install this version of numpy\n","# !pip install numpy==1.16.1\n","# an run the jupyter notebook from scratch."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qWMxG4LZYNrh"},"source":["# checking out the first line\n","print(x_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"42UGZaEzYNrl"},"source":["len(x_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"12wc860sYNrp"},"source":["# checking out the number of classes on our dataset.\n","print(set(y_train))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCTQBh6yYNrx"},"source":["print('Train sequences: {}'.format(len(x_train)))\n","print('Test sequences: {}'.format(len(x_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kDTqjh0bYNr1"},"source":["print('Pad sequences (samples x time)')\n","\n","x_train = sequence.pad_sequences(x_train,\n","                                 maxlen=maxlen,\n","                                 padding='pre',\n","                                 truncating='pre',\n","                                 value=0.0)\n","\n","x_test = sequence.pad_sequences(x_test,\n","                                maxlen=maxlen,\n","                                 padding='pre',\n","                                 truncating='pre',\n","                                 value=0.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_0umxujYNr4"},"source":["# help(sequence.pad_sequences)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOpsSHrjYNr8"},"source":["print('x_train shape: {}'.format(x_train.shape))\n","print('x_test shape: {}'.format(x_test.shape))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hWbzOOnNYNsA"},"source":["# checking again the first review with the padding.\n","print(x_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmjZxo8xYNsD"},"source":["print(y_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KhTZIdB1YNsG"},"source":["## How Convolutions Work"]},{"cell_type":"markdown","metadata":{"id":"lHUqMu6sYNsH"},"source":["<img src=\"http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif\">"]},{"cell_type":"markdown","metadata":{"id":"YFgJ2_dVYNsI"},"source":["## What are Strides and Padding"]},{"cell_type":"markdown","metadata":{"id":"RjC4RkzGYNsI"},"source":["<img src=\"http://deeplearning.net/software/theano/_images/numerical_padding_strides.gif\">"]},{"cell_type":"markdown","metadata":{"id":"uD35Lnz2YNsJ"},"source":["## How Max Pooling Works"]},{"cell_type":"markdown","metadata":{"id":"ErdJycJYYNsJ"},"source":["<img src=\"http://cs231n.github.io/assets/cnn/maxpool.jpeg\">"]},{"cell_type":"markdown","metadata":{"id":"ORHh2zpGYNsK"},"source":["## Build Text CNN Model"]},{"cell_type":"code","metadata":{"id":"97lCYEJrYNsK"},"source":["# network hyperparameters\n","embedding_dims = 50\n","\n","nof_filters = 25\n","\n","kernel_size = 3\n","\n","hidden_dims = 50"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tn-myHNjYNsN"},"source":["print('Build model...')\n","\n","model = Sequential()\n","\n","# we start off with an efficient embedding layer which maps\n","# our vocab indices into embedding_dims dimensions\n","model.add(Embedding(max_features,\n","                    embedding_dims,\n","                    input_length=maxlen))\n","\n","# model.add(Dropout(0.2))\n","\n","# we add a Convolution1D, which will learn filters\n","# word group filters of size filter_length:\n","\n","model.add(Conv1D(nof_filters, \n","                 kernel_size, \n","                 padding='valid',\n","                 activation='relu',\n","                 strides=1))\n","\n","model.add(GlobalMaxPooling1D())\n","\n","model.add(Dense(hidden_dims))\n","\n","model.add(Dropout(0.2))\n","model.add(Activation('relu'))\n","\n","# since we have a binary classification scheme, we selece ONE neuron with SIGMOID activation.\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ncgFOYiBYNsQ"},"source":["print( model.summary() )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9yb4l1A9YNsU"},"source":["model.compile(\n","    loss='binary_crossentropy',  # binary classification task\n","    optimizer='adam',\n","    metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPNBxDo_YNsX"},"source":["# fit hyperparameters\n","batch_size = 128\n","epochs = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"58KQZnAPYNsZ"},"source":["from tensorflow.python.keras.callbacks import EarlyStopping\n","\n","# early stopping callback\n","\n","es = keras.callbacks.EarlyStopping(\n","    monitor   = 'val_loss', # which metric we want to use as criterion to stop training\n","    min_delta = 0, # Minimum change in the monitored quantity to qualify as an improvement\n","    patience  = 4, # we 3 epochs before stopping\n","    verbose   = 1, # verbosity level\n","    mode      = 'auto',\n","    restore_best_weights = True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MohkkgA-YNsc"},"source":["history = model.fit(\n","    x_train,                # features\n","    y_train,                # labels\n","    epochs=epochs,          # numbers of epoch\n","    batch_size=batch_size,  # define batch size\n","    verbose=1,              # the most extended verbose\n","    validation_split=0.1,   # 90% for train and 10% for validation\n","    callbacks=[es]\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"auh_EZp8YNse"},"source":["score = model.evaluate(\n","    x_test,                  # features\n","    y_test,                  # labels\n","    batch_size=batch_size,   # batch size\n","    verbose=1                # the most extended verbose\n",")\n","\n","\n","print('\\nTest categorical_crossentropy:', score[0])\n","print('\\nTest accuracy:', score[1])"],"execution_count":null,"outputs":[]}]}