{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"c_keras_lstm_text_generation.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"pQRX1AZwIzsG"},"source":["# Big Data Content Analytics - AUEB\n","\n","## Text Generation using RNNs\n","\n","* Lab Assistant: George Perakis\n","* Email: gperakis[at]aeub.gr | perakisgeorgios[at]gmail.com"]},{"cell_type":"markdown","metadata":{"id":"fVEmQ-2cIzsL"},"source":["### Importing Modules"]},{"cell_type":"code","metadata":{"id":"45Ew356XIzsQ"},"source":["from __future__ import print_function\n","\n","import random\n","import sys\n","from typing import List, Tuple\n","\n","import numpy as np\n","from more_itertools import windowed\n","from tensorflow.python.keras.callbacks import ModelCheckpoint\n","from tensorflow.python.keras.layers import LSTM, Dense, Dropout\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.utils.data_utils import get_file\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-lEmnsaDIzsm"},"source":["### Text Generator Class"]},{"cell_type":"code","metadata":{"code_folding":[11,147],"id":"wSfkiDm1Izso"},"source":["class TextGenerator:\n","    \"\"\"\n","    Example script to generate text from Nietzsche's writings.\n","    \n","    At least 20 epochs are required before the generated text starts sounding \n","    coherent.\n","\n","    It is recommended to run this script on GPU, as recurrent networks are \n","    quite computationally intensive.\n","    \n","    If you try this script on new data, make sure your corpus\n","    has at least ~100k characters. ~1M is better.\n","    \"\"\"\n","\n","    def __init__(self, text_url: str = None, verbose: int = 0):\n","        \"\"\"\n","        \n","        :param text_url: \n","        :param verbose: \n","        \"\"\"\n","        if text_url is None:\n","            text_url = \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n","\n","        assert isinstance(text_url, str)\n","        assert isinstance(verbose, int)\n","\n","        self.verbose = verbose\n","        self.fname = text_url.split('/')[-1]\n","        self.text_url = text_url\n","\n","        self.model = None\n","\n","        self.characters = set()\n","        self.char2index = dict()\n","        self.index2char = dict()\n","        self.sentences = list()\n","        self.next_characters = list()\n","\n","        self.max_len = None\n","        self.step = None\n","\n","        self.text = None\n","\n","    def get_data(self):\n","        \"\"\"\n","\n","        :return:\n","        \"\"\"\n","        path = get_file(fname=self.fname, origin=self.text_url)\n","\n","        text = open(path).read().lower()\n","\n","        if self.verbose > 0:\n","            print(f'Corpus Length: {len(text)}')\n","            print('--------------------------------------------')\n","            print('Text snapshot')\n","            print(text[:150])\n","            print('--------------------------------------------')\n","\n","        self.text = text\n","\n","        return text\n","\n","    def prepare_data(self,\n","                     text,\n","                     max_len: int = 40,\n","                     step: int = 3):\n","        \"\"\"\n","        # cuts the text in semi-redundant sequences of max_len characters\n","\n","        :param text:\n","        :param max_len:\n","        :param step:\n","        :return:\n","        \"\"\"\n","        chars = set(text)\n","        print('total chars:', len(chars))\n","\n","        char2index = dict((c, i) for i, c in enumerate(chars))\n","        index2char = dict((i, c) for i, c in enumerate(chars))\n","\n","        sentences, next_chars = list(), list()\n","\n","        for w in tqdm(windowed(seq=text, n=(max_len + 1), step=step)):\n","            sent = ''.join(w[:-1])\n","            next_char = w[-1]\n","\n","            if next_char:\n","                sentences.append(sent)\n","                next_chars.append(next_char)\n","\n","        if self.verbose > 0:\n","            print(f'Number of extracted Sequences: {len(sentences)}')\n","            print(f'Number of extracted next characters: {len(next_chars)}')\n","            print(f'Number of characters: {len(chars)}')\n","            print(f'Length of Char2Index: {len(char2index)}')\n","            print(f'Length of Index2Char: {len(index2char)}')\n","\n","        self.characters = chars\n","        self.char2index = char2index\n","        self.index2char = index2char\n","        self.sentences = sentences\n","        self.next_characters = next_chars\n","        self.max_len = max_len\n","        self.step = step\n","\n","    def vectorize_inputs(\n","            self, sentences: List[str],\n","            next_chars: List[str]) -> Tuple[np.ndarray, np.ndarray]:\n","        \"\"\"\n","\n","        :param sentences:\n","        :param next_chars:\n","        :return:\n","        \"\"\"\n","        if self.verbose > 0:\n","            print('Vectorizing inputs...')\n","\n","        X = np.zeros((len(sentences), self.max_len, len(self.characters)),\n","                     dtype=np.bool)\n","\n","        y = np.zeros((len(sentences), len(self.characters)), dtype=np.bool)\n","\n","        for i, sentence in enumerate(sentences):\n","            for t, char in enumerate(sentence):\n","                X[i, t, self.char2index[char]] = 1\n","\n","            try:\n","                y[i, self.char2index[next_chars[i]]] = 1\n","\n","            except:\n","                print(i, next_chars[i])\n","                print()\n","                raise Exception()\n","\n","        if self.verbose > 0:\n","            print(f'X shape: {X.shape}')\n","            print(f'y shape: {y.shape}')\n","\n","        return X, y\n","\n","    @staticmethod\n","    def sample(a: np.ndarray, temperature: float = 1.0) -> np.ndarray:\n","        \"\"\"\n","\n","        :param a:\n","        :param temperature:\n","        :return:\n","        \"\"\"\n","        # helper function to sample an index from a probability array\n","        a = np.log(a) / temperature\n","        a = np.exp(a) / np.sum(np.exp(a))\n","\n","        return np.argmax(np.random.multinomial(1, a, 1))\n","\n","    def build_model(self, lstm_size: int = 10, dr: float = 0.0) -> Sequential:\n","        \"\"\"\n","\n","        :param lstm_size:\n","        :param dr:\n","        :return:\n","        \"\"\"\n","        # build the model: 2 stacked LSTM\n","\n","        if self.verbose > 0:\n","            print('Build model...')\n","\n","        model = Sequential()\n","\n","        model.add(LSTM(lstm_size,\n","                       return_sequences=True,\n","                       input_shape=(self.max_len, len(self.characters)),\n","                       name='lstm_layer_1'))\n","\n","        model.add(Dropout(dr, name='dropout_layer_1'))\n","\n","        model.add(LSTM(lstm_size,\n","                       return_sequences=False,\n","                       name='lstm_layer_2'))\n","\n","        model.add(Dropout(dr, name='dropout_layer_2'))\n","\n","        model.add(Dense(len(self.characters),\n","                        name='output_layer',\n","                        activation='softmax'))\n","\n","        model.compile(loss='categorical_crossentropy',\n","                      optimizer='adam')\n","\n","        self.model = model\n","\n","        print(model.summary())\n","\n","        return model\n","\n","    def fit_model(self,\n","                  X,\n","                  y,\n","                  n_repeat=10,\n","                  bs: int = 128,\n","                  epochs: int = 100,\n","                  diversity_list=None,\n","                  run_examples: bool = True):\n","        \"\"\"\n","        \n","        :param X: \n","        :param y: \n","        :param n_repeat: \n","        :param bs: \n","        :param epochs: \n","        :param diversity_list: \n","        :param run_examples: \n","        :return: \n","        \"\"\"\n","\n","        # train the model, output generated text after each iteration\n","        if diversity_list is None:\n","            diversity_list = [0.2, 0.5, 1.0, 1.2]\n","\n","        fpath = 'text_generator.h5'\n","\n","        for iteration in range(1, n_repeat + 1):\n","            print()\n","            print('-' * 50)\n","            print('Iteration', iteration)\n","\n","            md = ModelCheckpoint(filepath=fpath, monitor='loss', verbose=1,\n","                                 save_best_only=True)\n","\n","            self.model.fit(X, y, batch_size=bs, epochs=epochs, verbose=2,\n","                           callbacks=[md])\n","\n","            if run_examples:\n","\n","                start_index = random.randint(0,\n","                                             len(self.text) - self.max_len - 1)\n","                #\n","                for diversity in diversity_list:\n","                    print()\n","                    print(f'----- Diversity: {diversity}')\n","                    #\n","                    generated_text = ''\n","                    sentence = self.text[\n","                               start_index: start_index + self.max_len]\n","\n","                    generated_text += sentence\n","\n","                    print(\n","                        f'----- Generating with seed: \"\"{sentence}\"\" ')\n","\n","                    sys.stdout.write(generated_text)\n","\n","                    #\n","                    for i in range(150):\n","\n","                        x = np.zeros((1, self.max_len, len(self.characters)))\n","\n","                        for t, char in enumerate(sentence):\n","                            x[0, t, self.char2index[char]] = 1.\n","\n","                        preds = self.model.predict(x, verbose=0)[0]\n","\n","                        try:\n","                            next_index = self.sample(preds, diversity)\n","                            next_char = self.index2char[next_index]\n","                        except:\n","                            next_char = ''\n","\n","                        generated_text += next_char\n","                        sentence = sentence[1:] + next_char\n","\n","                        sys.stdout.write(next_char)\n","                        sys.stdout.flush()\n","\n","                    print()\n","\n","        return self.model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[0],"id":"MOd7xAmQIzsy"},"source":["def run_example(max_len=40, step=3, lstm_size=100, dropout=0.0,\n","                n_samples=10_000, n_repeat=5, epochs=100, batch_size=512,\n","                div_list=None, run_examples=True):\n","    \"\"\"\n","\n","    :param max_len:\n","    :param step:\n","    :param lstm_size:\n","    :param dropout:\n","    :param n_samples:\n","    :param n_repeat:\n","    :param epochs:\n","    :param batch_size:\n","    :param div_list:\n","    :param run_examples:\n","    :return:\n","    \"\"\"\n","\n","    tgo = TextGenerator()\n","\n","    text = tgo.get_data()\n","\n","    tgo.prepare_data(text=text, max_len=max_len, step=step)\n","\n","    X, y = tgo.vectorize_inputs(sentences=tgo.sentences,\n","                                next_chars=tgo.next_characters)\n","\n","    if n_samples:\n","        X = X[:n_samples, :, :]\n","        y = y[:n_samples, :]\n","\n","    tgo.build_model(lstm_size=lstm_size, dr=dropout)\n","\n","    if div_list is None:\n","        div_list = [0.2, 0.5, 1.0, 1.2]\n","\n","    tgo.fit_model(X=X, y=y, n_repeat=n_repeat, epochs=epochs,\n","                  bs=batch_size, diversity_list=div_list,\n","                  run_examples=run_examples)\n","\n","    return tgo.model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fcMngAj7Izs6"},"source":["### Run Example"]},{"cell_type":"code","metadata":{"id":"hvuC65p9Izs7","scrolled":false},"source":["run_example(max_len=40,\n","            step=3,\n","            lstm_size=100,\n","            dropout=0.0,\n","            n_samples=10_000,\n","            epochs=5,\n","            batch_size=1024,\n","            div_list=None,\n","            run_examples=True)"],"execution_count":null,"outputs":[]}]}