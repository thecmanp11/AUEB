{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"a_imdb_bidirectional_lstm.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"JAk2RXzqE0io"},"source":["# Big Data Content Analytics - AUEB\n","\n","## Introduction to Recurrent Neural Networks\n","\n","* Lab Assistant: George Perakis\n","* Email: gperakis[at]aeub.gr | perakisgeorgios[at]gmail.com"]},{"cell_type":"markdown","metadata":{"id":"Ar9yCY12E0iq"},"source":["<img src=\"https://i.stack.imgur.com/aTDpS.png\">"]},{"cell_type":"markdown","metadata":{"id":"xaYKDa0EE0iq"},"source":["<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png\">"]},{"cell_type":"markdown","metadata":{"id":"mk_VKRfEE0ir"},"source":["<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png\">"]},{"cell_type":"markdown","metadata":{"id":"9MKl7dzLE0is"},"source":["<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png\">"]},{"cell_type":"markdown","metadata":{"id":"T446LSIsE0it"},"source":["<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png\">"]},{"cell_type":"markdown","metadata":{"id":"0YGt6rn4E0iu"},"source":["<img src=\"https://gblobscdn.gitbook.com/assets%2F-LvMRntv-nKvtl7WOpCz%2F-LvMRp9FltcwEeVxPYFs%2F-LvMRquVdf276Mkd6Lkb%2FRNN_Unrolling.png?alt=media\">"]},{"cell_type":"markdown","metadata":{"id":"PJAP0fI1E0iu"},"source":["### Import Modules"]},{"cell_type":"code","metadata":{"id":"H7u-L9oaE0iv"},"source":["from __future__ import print_function\n","\n","import numpy as np\n","\n","np.random.seed(1337)  # for reproducibility\n","\n","from tensorflow.python.keras.preprocessing import sequence\n","from tensorflow.python.keras.models import Model\n","from tensorflow.python.keras.layers import Dense, Embedding, LSTM, Input, Concatenate, Bidirectional, concatenate\n","from tensorflow.python.keras.datasets import imdb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8x-NGscZE0i0"},"source":["### Build Models functions"]},{"cell_type":"code","metadata":{"code_folding":[],"id":"3gzBbSIAE0i1"},"source":["def build_model(max_len: int,\n","                max_feats: int,\n","                emb_dimensions: int,\n","                n_outputs: int = 1):\n","    \"\"\"\n","\n","    :param max_len:\n","    :param max_feats:\n","    :param emb_dimensions:\n","    :param n_outputs:\n","    :return:\n","    \"\"\"\n","    # this is the placeholder tensor for the input sequences\n","    sequence = Input(shape=(max_len,), dtype='int32')\n","\n","    # this embedding layer will transform the sequences of integers into vectors of size 128\n","    emb_layer = Embedding(max_feats, emb_dimensions, input_length=max_len)\n","\n","    embedded = emb_layer(sequence)\n","\n","    # apply forwards LSTM\n","    forwards = LSTM(64)(embedded)\n","\n","    # apply backwards LSTM\n","    backwards = LSTM(64, go_backwards=True)(embedded)\n","\n","    # concatenate the outputs of the 2 LSTMs\n","    merged = concatenate([forwards, backwards], axis=-1)\n","\n","    # after_dp = Dropout(0.5)(merged)\n","    # output = Dense(1, activation='sigmoid')(after_dp)\n","\n","    if n_outputs == 1:\n","        output = Dense(n_outputs,\n","                       activation='sigmoid')(merged)\n","\n","        model = Model(inputs=[sequence],\n","                      outputs=[output])\n","\n","        # try using different optimizers and different optimizer configs\n","        model.compile('adam',\n","                      'binary_crossentropy',\n","                      metrics=['accuracy'])\n","\n","    else:\n","        output = Dense(n_outputs, activation='softmax')(merged)\n","\n","        model = Model(inputs=[sequence], outputs=[output])\n","\n","        # try using different optimizers and different optimizer configs\n","        model.compile('adam',\n","                      'categorical_crossentropy',\n","                      metrics=['accuracy'])\n","\n","    print(model.summary())\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[],"id":"TKr3iQ5lE0i4"},"source":["def build_model_2(max_len: int,\n","                  max_feats: int,\n","                  emb_dimensions: int,\n","                  n_outputs: int = 1):\n","    \"\"\"\n","\n","    :param max_len:\n","    :param max_feats:\n","    :param emb_dimensions:\n","    :param n_outputs:\n","    :return:\n","    \"\"\"\n","    # this is the placeholder tensor for the input sequences\n","    sequence = Input(shape=(max_len,), dtype='int32')\n","\n","    # this embedding layer will transform the sequences of integers into \n","    # vectors of size 128\n","    emb_layer = Embedding(max_feats, emb_dimensions, input_length=max_len)\n","\n","    embedded = emb_layer(sequence)\n","\n","    lstm = Bidirectional(LSTM(64, return_sequences=False))(embedded)\n","    # lstm = Bidirectional(LSTM(64))(embedded)\n","\n","    # after_dp = Dropout(0.5)(merged)\n","    # output = Dense(1, activation='sigmoid')(after_dp)\n","\n","    if n_outputs == 1:\n","        output = Dense(n_outputs, activation='sigmoid')(lstm)\n","\n","        model = Model(inputs=[sequence], outputs=[output])\n","\n","        # try using different optimizers and different optimizer configs\n","        model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n","\n","    else:\n","        output = Dense(n_outputs, activation='softmax')(lstm)\n","\n","        model = Model(inputs=[sequence], outputs=[output])\n","\n","        # try using different optimizers and different optimizer configs\n","        model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n","\n","    print(model.summary())\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LHX1F-gQE0i9"},"source":["### Load Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ekZtpczvE0i-","executionInfo":{"status":"ok","timestamp":1624959692415,"user_tz":-180,"elapsed":5399,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"5fa5e710-0aa5-43f3-f42b-e5f189a97bbd"},"source":["# Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative).\n","# Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers).\n","max_features = 20000\n","\n","print('Loading data...')\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading data...\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"],"name":"stderr"},{"output_type":"stream","text":["25000 train sequences\n","25000 test sequences\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ch8o2W-GE0jC","scrolled":true,"executionInfo":{"status":"ok","timestamp":1624959692417,"user_tz":-180,"elapsed":20,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"edbe80a9-0c87-4ef4-9f79-4c80b40125b5"},"source":["print(x_train[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a10OFSiHE0jG"},"source":["### Set Hyper-parameters"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifCM75NiE0jH","executionInfo":{"status":"ok","timestamp":1624959692417,"user_tz":-180,"elapsed":14,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"e480e04e-624f-4c2b-ef2a-90cb2df3da75"},"source":["maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n","\n","batch_size = 128\n","emb_dim = 100\n","\n","print(f'Max-Length: {maxlen}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Max-Length: 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1uKce0SGE0jL","executionInfo":{"status":"ok","timestamp":1624959693266,"user_tz":-180,"elapsed":859,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"3e39340b-8867-41a4-c567-75f53a196f6f"},"source":["print(\"Pad sequences (samples x time)\")\n","\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","\n","print(f'X_train shape: {x_train.shape}')\n","print(f'X_test shape: {x_test.shape}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pad sequences (samples x time)\n","X_train shape: (25000, 100)\n","X_test shape: (25000, 100)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FUChV1ctE0jO"},"source":["y_train = np.array(y_train)\n","y_test = np.array(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAqqhGBSNU9R","executionInfo":{"status":"ok","timestamp":1624959696797,"user_tz":-180,"elapsed":11,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"e09b4d72-d4a7-4c2f-e848-402de21daa89"},"source":["y_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"VftsqqqGE0jR"},"source":["### Build Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-hGOkanE0jS","executionInfo":{"status":"ok","timestamp":1624959706252,"user_tz":-180,"elapsed":5705,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"b3f19a24-f3b1-4cb8-de09-4665f008ea97"},"source":["rnn_model = build_model_2(max_len=maxlen, max_feats=max_features, emb_dimensions=emb_dim)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 100)]             0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 100, 100)          2000000   \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 128)               84480     \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 129       \n","=================================================================\n","Total params: 2,084,609\n","Trainable params: 2,084,609\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IpteCbd9E0jW","executionInfo":{"status":"ok","timestamp":1624960273573,"user_tz":-180,"elapsed":567327,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"e36e87f4-3fb4-4872-fbca-8a77226528a2"},"source":["print('Train...')\n","\n","train_samples = 20_000\n","\n","rnn_model.fit(\n","    x_train,\n","    y_train,\n","    batch_size=batch_size,\n","    epochs=5,\n","    validation_split=0.20\n",")\n","\n","\n","# Train a Bidirectional LSTM on the IMDB sentiment classification task.\n","# Accuracy after 5 epochs on CPU: ~0.83 \n","# Time per epoch on GPU (Colab): ~120sec.\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train...\n","Epoch 1/5\n","157/157 [==============================] - 122s 733ms/step - loss: 0.4594 - accuracy: 0.7738 - val_loss: 0.3399 - val_accuracy: 0.8516\n","Epoch 2/5\n","157/157 [==============================] - 110s 703ms/step - loss: 0.2392 - accuracy: 0.9076 - val_loss: 0.3579 - val_accuracy: 0.8452\n","Epoch 3/5\n","157/157 [==============================] - 114s 725ms/step - loss: 0.1599 - accuracy: 0.9444 - val_loss: 0.4362 - val_accuracy: 0.8378\n","Epoch 4/5\n","157/157 [==============================] - 111s 705ms/step - loss: 0.1079 - accuracy: 0.9646 - val_loss: 0.4746 - val_accuracy: 0.8366\n","Epoch 5/5\n","157/157 [==============================] - 110s 703ms/step - loss: 0.0656 - accuracy: 0.9798 - val_loss: 0.6421 - val_accuracy: 0.8230\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f390b965490>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"rYFIXx6uE0jZ"},"source":["### Model Evaluation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sxqzjdx0E0ja","executionInfo":{"status":"ok","timestamp":1624960284689,"user_tz":-180,"elapsed":11124,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"c31d9c26-dd94-4042-abd5-cfcc9d69b260"},"source":["score = rnn_model.evaluate(\n","    x_test,  # features\n","    y_test,  # labels\n","    batch_size=batch_size,  # batch size\n","    verbose=1  # the most extended verbose\n",")\n","\n","print('\\nTest crossentropy:', score[0])\n","print('\\nTest accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["196/196 [==============================] - 11s 54ms/step - loss: 0.6828 - accuracy: 0.8162\n","\n","Test crossentropy: 0.682769775390625\n","\n","Test accuracy: 0.8162400126457214\n"],"name":"stdout"}]}]}