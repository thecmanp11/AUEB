{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"b_keras_babi_rnn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"9XSzCYrMXVS2"},"source":["# Big Data Content Analytics - AUEB\n","\n","## Introduction to Question - Answering Tasks using RNNs\n","\n","* Lab Assistant: George Perakis\n","* Email: gperakis[at]aeub.gr | perakisgeorgios[at]gmail.com"]},{"cell_type":"markdown","metadata":{"id":"urQaE-unXVS3"},"source":["### Importing Modules"]},{"cell_type":"code","metadata":{"id":"F6y6aXNkXVS4","executionInfo":{"status":"ok","timestamp":1624966076135,"user_tz":-180,"elapsed":1750,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["from __future__ import print_function\n","\n","import re\n","import tarfile\n","from functools import reduce\n","from pprint import pprint\n","from typing import List, Tuple\n","\n","import numpy as np\n","from tensorflow.python.keras import layers\n","from tensorflow.python.keras.layers import recurrent, Input, Embedding, RepeatVector, Dropout, Dense, LSTM\n","from tensorflow.python.keras.models import Model\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.python.keras.utils.data_utils import get_file\n","from tqdm import tqdm"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U7B35K-uXVS_"},"source":["### ETL and Configuration functions"]},{"cell_type":"code","metadata":{"code_folding":[0],"id":"ldthQ3hAXVTA","executionInfo":{"status":"ok","timestamp":1624966076136,"user_tz":-180,"elapsed":31,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["def tokenize(sent: str) -> List[str]:\n","    \"\"\"\n","    Return the tokens of a sentence including punctuation.\n","\n","    >>> tokenize('Bob dropped the apple. Where is the apple?')\n","    >>> ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n","\n","\n","    :param sent: str. A sentence\n","    :return: A list of tokens\n","    \"\"\"\n","    tokens = list()\n","    \n","    for token in re.split('(\\w+)?', sent):\n","        if token is None:\n","            continue\n","        \n","        if token.strip():\n","            tokens.append(token.strip())\n","            \n","    return tokens"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[0],"id":"HyrlDHLHXVTE","executionInfo":{"status":"ok","timestamp":1624966076137,"user_tz":-180,"elapsed":29,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["def parse_stories(lines: List[bytes],\n","                  only_supporting: bool = False,\n","                  verbose: int = 1) -> List:\n","    \"\"\"\n","    Parse stories provided in the bAbi tasks format\n","\n","\n","\n","    lines example:\n","    [b'1 Mary moved to the bathroom.\\n',\n","     b'2 Sandra journeyed to the bedroom.\\n',\n","     b'3 Mary got the football there.\\n',\n","     b'4 John went to the kitchen.\\n',\n","     b'5 Mary went back to the kitchen.\\n',\n","     b'6 Mary went back to the garden.\\n',\n","     b'7 Where is the football? \\tgarden\\t3 6\\n',\n","     b'8 Sandra went back to the office.\\n',\n","     b'9 John moved to the office.\\n',\n","     b'10 Sandra journeyed to the hallway.\\n',\n","     b'11 Daniel went back to the kitchen.\\n',\n","     b'12 Mary dropped the football.\\n',\n","     b'13 John got the milk there.\\n',\n","     b'14 Where is the football? \\tgarden\\t12 6\\n',\n","     b'15 Mary took the football there.\\n',\n","     b'16 Sandra picked up the apple there.\\n',\n","     b'17 Mary travelled to the hallway.\\n',\n","     b'18 John journeyed to the kitchen.\\n',\n","     b'19 Where is the football? \\thallway\\t15 17\\n',\n","     b'20 John moved to the hallway.\\n',\n","     b'21 Sandra left the apple.\\n',\n","     b'22 Where is the apple? \\thallway\\t21 10\\n',\n","     b'23 Mary got the apple there.\\n',\n","     b'24 John travelled to the garden.\\n',\n","     b'25 John went back to the hallway.\\n',\n","     b'26 John went back to the bedroom.\\n',\n","     b'27 Mary journeyed to the bedroom.\\n',\n","     b'28 John journeyed to the kitchen.\\n',\n","     b'29 John left the milk.\\n',\n","     b'30 Mary left the apple.\\n',\n","     b'31 Where is the milk? \\tkitchen\\t29 28\\n',   --> here is the question and the response\n","\n","    :param lines: A list of bytes string. Each row has an id and a text\n","    :param only_supporting: bool. If True, only the sentences that support the answer are kept.\n","    :param verbose: int. Verbosity level\n","\n","    :return:\n","    \"\"\"\n","\n","    data, story = list(), list()\n","\n","    for line in tqdm(lines, desc='Parsing Lines', unit='story_line'):\n","\n","        # convert bytes to string\n","        line = line.decode('utf-8').strip()\n","\n","        # getting the id and the rest of the text\n","        nid, line = line.split(' ', 1)  # splits only in the first space (creates a 2 dimension list]\n","\n","        # convert the id to integer\n","        nid = int(nid)\n","\n","        if nid == 1:  # new story\n","            story = list()\n","\n","        if '\\t' in line:\n","            quest, ans, supporting = line.split('\\t')\n","\n","            # tokenizing the question\n","            quest = tokenize(quest)\n","\n","            if only_supporting:\n","                # Only select the related sub_story\n","                supporting = map(int, supporting.split())\n","                sub_story = [story[i - 1] for i in supporting]\n","\n","            else:\n","                # Provide all the sub_stories\n","                sub_story = [x for x in story if x]\n","\n","            data.append((sub_story, quest, ans))\n","\n","            story.append('')\n","\n","        else:\n","            # split the sentence into tokens\n","            sent = tokenize(line)\n","            story.append(sent)\n","\n","    if verbose > 0:\n","        print()\n","        pprint(data[0])\n","\n","    return data"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[0],"id":"bcmIRB6UXVTJ","executionInfo":{"status":"ok","timestamp":1624966076138,"user_tz":-180,"elapsed":28,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["def get_stories(f, only_supporting: bool = False,\n","                max_length: int = None) -> List[Tuple[List[str], List[str], str]]:\n","    \"\"\"\n","    Given a file name:\n","    a) read the file\n","    b) retrieve the stories\n","    c) convert the sentences into a single story.\n","\n","    If max_length is supplied, any stories longer than 'max_length' tokens will be discarded.\n","\n","    :param f:\n","    :param only_supporting:\n","    :param max_length:\n","    :return:\n","    \"\"\"\n","\n","    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n","\n","    flatten = lambda info: reduce(lambda x, y: x + y, info)\n","\n","    # output = [(flatten(story), q, answer) for story, q, answer in data\n","    # if not max_length or len(flatten(story)) < max_length]\n","\n","    output = list()\n","\n","    for story, q, answer in data:\n","\n","        if not max_length or len(flatten(story)) < max_length:\n","            # creates a tuple with 3 inputs\n","            # the first inputs is a list of all the tokens for the stories\n","            # the second is a list of the tokens for the question\n","            # the thirds is the response\n","            output.append((flatten(story), q, answer))\n","\n","    return output"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[0],"id":"lsYNhZGXXVTN","executionInfo":{"status":"ok","timestamp":1624966076138,"user_tz":-180,"elapsed":26,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["def vectorize_stories(data: List[Tuple[List[str], List[str], str]],\n","                      word_to_idx: dict,\n","                      story_max_len: int,\n","                      query_max_len: int) -> Tuple:\n","    \"\"\"\n","    This function vectorizes the data\n","    The data consists of a Tuple containing the following\n","    1) A list of tokens depicting the story\n","    2) A list of tokens depicting the question\n","    3) A token depicting the response\n","    \n","    Vectorizes the stories, the questions, and the responses\n","    \n","    :param data:\n","    :param word_to_idx:\n","    :param story_max_len:\n","    :param query_max_len:\n","    :return:\n","    \"\"\"\n","\n","    xs = []  # list for the stories\n","    xqs = []  # list for the questions\n","    ys = []  # list for the outputs (answers)\n","\n","    for story, query, answer in data:\n","        x = [word_to_idx[w.strip().lower()] for w in story]  # indexes of the tokens for each story\n","        xq = [word_to_idx[w.strip().lower()] for w in query]  # indexes of the tokens for each question\n","\n","        # let's not forget that index 0 is reserved\n","        y = np.zeros(len(word_to_idx) + 1)  # creates a list of zeros\n","\n","        # put one 1 in where the token of the response is located (one-hot encoding the answers since it's answer\n","        # is a single word\n","        y[word_to_idx[answer.strip().lower()]] = 1\n","\n","        xs.append(x)\n","        xqs.append(xq)\n","        ys.append(y)\n","\n","    # padding the story sequences\n","    pad_xs = pad_sequences(xs,\n","                           maxlen=story_max_len)\n","\n","    # padding the question sequences\n","    pad_xqs = pad_sequences(xqs,\n","                            maxlen=query_max_len)\n","\n","    # converting the list of np.arrays to a single np.ndarray\n","    np_ys = np.array(ys)\n","\n","    # returns a tuple of three numpy arrays.\n","    return pad_xs, pad_xqs, np_ys"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[0],"id":"uuBuWKwcXVTR","executionInfo":{"status":"ok","timestamp":1624966076139,"user_tz":-180,"elapsed":25,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["def fetch_file():\n","    \"\"\"\n","    fetches the file if not existent.\n","    :return:\n","    \"\"\"\n","    try:\n","        fpath = get_file(fname='babi-tasks-v1-2.tar.gz',\n","                         origin='https://s3.amazonaws.com/text-datasets/'\n","                                'babi_tasks_1-20_v1-2.tar.gz')\n","    except:\n","        print('Error downloading dataset, please download it manually:\\n'\n","              '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n","              '.tar.gz\\n'\n","              '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n","        raise\n","\n","    return fpath"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[0],"id":"VnkZvRtTXVTV","executionInfo":{"status":"ok","timestamp":1624966076140,"user_tz":-180,"elapsed":24,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["class Config:\n","    \"\"\"\n","    Configuration variables used for the model build and model fit.\n","    \"\"\"\n","    RNN = recurrent.LSTM\n","    EMBED_HIDDEN_SIZE = 50\n","    SENT_HIDDEN_SIZE = 100\n","    QUERY_HIDDEN_SIZE = 100\n","    BATCH_SIZE = 64\n","    EPOCHS = 20"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[],"id":"WD0p16LdXVTa","executionInfo":{"status":"ok","timestamp":1624966076140,"user_tz":-180,"elapsed":19,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["def build_model(story_max_len: int,\n","                query_max_len: int,\n","                embed_hidden_size: Config.EMBED_HIDDEN_SIZE) -> Model:\n","    \"\"\"\n","\n","    :param story_max_len: int. Needed for the sentence (story) input\n","    :param query_max_len: int. Needed for the question input.\n","    :param embed_hidden_size: int. The number of hidden layers to use for the RNN layers.\n","    :return: A keras Model (not sequential)\n","    \"\"\"\n","    assert story_max_len > 0\n","    assert query_max_len > 0\n","    assert embed_hidden_size > 0\n","\n","    print('Build model...')\n","\n","    sentence = Input(shape=(story_max_len,),\n","                     dtype='int32',\n","                     name='sentence_input')\n","\n","    encoded_sentence = Embedding(vocab_size,\n","                                 embed_hidden_size,\n","                                 name='sentence_embedding')(sentence)\n","\n","    question = Input(shape=(query_max_len,),\n","                     dtype='int32',\n","                     name='question_input')\n","\n","    encoded_question = Embedding(vocab_size,\n","                                 embed_hidden_size,\n","                                 name='question_embedding')(question)\n","\n","    encoded_question = LSTM(embed_hidden_size,\n","                            name='lstm_question')(encoded_question)\n","\n","    encoded_question = RepeatVector(story_max_len,\n","                                    name='lstm_question_3d')(encoded_question)\n","\n","    merged = layers.add([encoded_sentence,\n","                         encoded_question])\n","\n","    merged = LSTM(embed_hidden_size)(merged)\n","\n","    merged = Dropout(0.3)(merged)\n","\n","    predictions = Dense(vocab_size,\n","                        activation='softmax')(merged)\n","\n","    model = Model([sentence, question], predictions)\n","\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    print('Done building model...')\n","    print(model.summary())\n","\n","    return model"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kRzAqpXQXVTd"},"source":["### ETL Pipeline"]},{"cell_type":"markdown","metadata":{"id":"lP_diS-tXVTe"},"source":["#### Loading Dataset"]},{"cell_type":"code","metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"nGkGl-OuXVTe","executionInfo":{"status":"ok","timestamp":1624966076141,"user_tz":-180,"elapsed":19,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"9449071e-b0be-4087-c2fe-dd23df55f9b6"},"source":["# fetch data if not present\n","path = fetch_file()\n","\n","print(path)\n","\n","# Default QA1 with 1000 samples\n","# challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'\n","# QA1 with 10,000 samples\n","# challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n","# QA2 with 1000 samples"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/root/.keras/datasets/babi-tasks-v1-2.tar.gz\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rTxyPg5VXVTi"},"source":["#### Select spesific challenge"]},{"cell_type":"code","metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"swaFWC2KXVTi","executionInfo":{"status":"ok","timestamp":1624966077622,"user_tz":-180,"elapsed":1494,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"3ef6afbd-de97-43fb-f350-f15a92c53215"},"source":["challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n","# QA2 with 10,000 samples\n","# challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n","\n","with tarfile.open(path) as tar:\n","    train_extract = tar.extractfile(challenge.format('train'))\n","    text_extract = tar.extractfile(challenge.format('test'))\n","\n","    train = get_stories(train_extract)\n","    print()\n","    test = get_stories(text_extract)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Parsing Lines: 100%|██████████| 5338/5338 [00:00<00:00, 34040.36story_line/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","([['Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n","  ['Sandra', 'journeyed', 'to', 'the', 'bedroom', '.'],\n","  ['Mary', 'got', 'the', 'football', 'there', '.'],\n","  ['John', 'went', 'to', 'the', 'kitchen', '.'],\n","  ['Mary', 'went', 'back', 'to', 'the', 'kitchen', '.'],\n","  ['Mary', 'went', 'back', 'to', 'the', 'garden', '.']],\n"," ['Where', 'is', 'the', 'football', '?'],\n"," 'garden')\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Parsing Lines: 100%|██████████| 5398/5398 [00:00<00:00, 125147.05story_line/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","([['Mary', 'got', 'the', 'milk', 'there', '.'],\n","  ['John', 'moved', 'to', 'the', 'bedroom', '.'],\n","  ['Sandra', 'went', 'back', 'to', 'the', 'kitchen', '.'],\n","  ['Mary', 'travelled', 'to', 'the', 'hallway', '.']],\n"," ['Where', 'is', 'the', 'milk', '?'],\n"," 'hallway')\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Z8wacmvAXVTm"},"source":["#### Build Vocabulary"]},{"cell_type":"code","metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"aUNRbI5YXVTn","executionInfo":{"status":"ok","timestamp":1624966077623,"user_tz":-180,"elapsed":22,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"f392912e-3e85-4f2c-b5c6-3a6824346d58"},"source":["vocab = set()\n","# unifying train and test to get all the tokens\n","# for story, question, answer\n","for s, q, a in train + test:\n","    sample_tokens = [token.strip().lower() for token in s + q + [a]]\n","    vocab |= set(sample_tokens)\n","\n","vocab = sorted(vocab)\n","print(len(vocab))\n","\n","# Reserve 0 for masking via pad_sequences\n","vocab_size = len(vocab) + 1"],"execution_count":11,"outputs":[{"output_type":"stream","text":["35\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"FC_HavimXVTq","executionInfo":{"status":"ok","timestamp":1624966077623,"user_tz":-180,"elapsed":19,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"a59b43b0-6ff0-425f-c07a-31e527727d52"},"source":["# creating a dictionary with words (tokens) as keys and index as value (starting from 1)\n","word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n","\n","print(word_idx)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["{'.': 1, '?': 2, 'apple': 3, 'back': 4, 'bathroom': 5, 'bedroom': 6, 'daniel': 7, 'discarded': 8, 'down': 9, 'dropped': 10, 'football': 11, 'garden': 12, 'got': 13, 'grabbed': 14, 'hallway': 15, 'is': 16, 'john': 17, 'journeyed': 18, 'kitchen': 19, 'left': 20, 'mary': 21, 'milk': 22, 'moved': 23, 'office': 24, 'picked': 25, 'put': 26, 'sandra': 27, 'the': 28, 'there': 29, 'to': 30, 'took': 31, 'travelled': 32, 'up': 33, 'went': 34, 'where': 35}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WOR8x9y5XVTt"},"source":["#### Calculate Maximum Length for the stories and the questions"]},{"cell_type":"code","metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"8DJL4PJ4XVTu","executionInfo":{"status":"ok","timestamp":1624966077625,"user_tz":-180,"elapsed":16,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"ef6f25a3-c5d4-473b-b412-e7e4dad20a97"},"source":["# calculates the max length of all the lengths of the tokens for each story\n","story_maxlen = max(map(len, (x for x, _, _ in train + test)))\n","\n","# calculates the max length of all the lengths of the tokens for each query\n","query_maxlen = max(map(len, (x for _, x, _ in train + test)))\n","\n","print(story_maxlen)\n","print(query_maxlen)\n","\n","print(f'RNN: {Config.RNN} \\n Embed: {Config.EMBED_HIDDEN_SIZE} \\n Sent: {Config.SENT_HIDDEN_SIZE} \\n Query: {Config.QUERY_HIDDEN_SIZE}')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["552\n","5\n","RNN: <class 'tensorflow.python.keras.layers.recurrent.LSTM'> \n"," Embed: 50 \n"," Sent: 100 \n"," Query: 100\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N4i-CvzEXVTx"},"source":["#### Vectorize Data"]},{"cell_type":"code","metadata":{"code_folding":[],"id":"zlp9Wo2PXVTx","executionInfo":{"status":"ok","timestamp":1624966077626,"user_tz":-180,"elapsed":14,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["x, xq, y = vectorize_stories(data=train,\n","                             word_to_idx=word_idx,\n","                             story_max_len=story_maxlen,\n","                             query_max_len=query_maxlen)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[],"id":"JTySY6zVXVT1","executionInfo":{"status":"ok","timestamp":1624966077627,"user_tz":-180,"elapsed":14,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}}},"source":["tx, txq, ty = vectorize_stories(data=test,\n","                                word_to_idx=word_idx,\n","                                story_max_len=story_maxlen,\n","                                query_max_len=query_maxlen)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"LdI47pT-XVT4","executionInfo":{"status":"ok","timestamp":1624966077627,"user_tz":-180,"elapsed":14,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"384044bf-1813-4d05-a8ba-8751fbb7853e"},"source":["print(f'vocab = {vocab}', end='\\n\\n')\n","\n","print(f'Story_maxlen= {story_maxlen} \\n'\n","      f'Query_maxlen = {query_maxlen}')\n","\n","print(f'X-Story.shape = {x.shape}')\n","print(f'X-Question.shape = {xq.shape}')\n","print(f'y-response.shape = {y.shape}')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["vocab = ['.', '?', 'apple', 'back', 'bathroom', 'bedroom', 'daniel', 'discarded', 'down', 'dropped', 'football', 'garden', 'got', 'grabbed', 'hallway', 'is', 'john', 'journeyed', 'kitchen', 'left', 'mary', 'milk', 'moved', 'office', 'picked', 'put', 'sandra', 'the', 'there', 'to', 'took', 'travelled', 'up', 'went', 'where']\n","\n","Story_maxlen= 552 \n","Query_maxlen = 5\n","X-Story.shape = (1000, 552)\n","X-Question.shape = (1000, 5)\n","y-response.shape = (1000, 36)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CHJrAg0sXVT7"},"source":["### Build Model"]},{"cell_type":"code","metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"N3KzhzvGXVT8","executionInfo":{"status":"ok","timestamp":1624966078771,"user_tz":-180,"elapsed":622,"user":{"displayName":"George Perakis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwB049kbpiKN5uR3kVv2MHaokXYMTzFbv5IDCVfrg=s64","userId":"05726012581152193594"}},"outputId":"87d618e6-3e27-4a45-9c9b-2ec1ede4f3fc"},"source":["qa_model = build_model(story_max_len=story_maxlen,\n","                       query_max_len=query_maxlen,\n","                       embed_hidden_size=Config.EMBED_HIDDEN_SIZE)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Build model...\n","Done building model...\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","question_input (InputLayer)     [(None, 5)]          0                                            \n","__________________________________________________________________________________________________\n","question_embedding (Embedding)  (None, 5, 50)        1800        question_input[0][0]             \n","__________________________________________________________________________________________________\n","sentence_input (InputLayer)     [(None, 552)]        0                                            \n","__________________________________________________________________________________________________\n","lstm_question (LSTM)            (None, 50)           20200       question_embedding[0][0]         \n","__________________________________________________________________________________________________\n","sentence_embedding (Embedding)  (None, 552, 50)      1800        sentence_input[0][0]             \n","__________________________________________________________________________________________________\n","lstm_question_3d (RepeatVector) (None, 552, 50)      0           lstm_question[0][0]              \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 552, 50)      0           sentence_embedding[0][0]         \n","                                                                 lstm_question_3d[0][0]           \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     (None, 50)           20200       add[0][0]                        \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 50)           0           lstm[0][0]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 36)           1836        dropout[0][0]                    \n","==================================================================================================\n","Total params: 45,836\n","Trainable params: 45,836\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YljJZ87zXVT_"},"source":["### Train Model"]},{"cell_type":"code","metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"beN8EntQXVT_","outputId":"5561f8f2-e1ba-4bd3-87e9-f6474e4c06d8"},"source":["print('Training')\n","qa_model.fit(\n","    [x, xq], y,\n","    batch_size=Config.BATCH_SIZE,\n","    epochs=Config.EPOCHS,\n","    validation_split=0.05,\n","    verbose=1\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training\n","Epoch 1/20\n","15/15 [==============================] - 32s 2s/step - loss: 3.4663 - accuracy: 0.1758 - val_loss: 3.0439 - val_accuracy: 0.3000\n","Epoch 2/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"07VIxit_XVUD"},"source":["### Evaluate Model"]},{"cell_type":"code","metadata":{"code_folding":[],"id":"rcH4PJg4XVUD"},"source":["loss, acc = qa_model.evaluate([tx, txq], ty,\n","                              batch_size=Config.BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[],"id":"8jDeqrX_XVUH"},"source":["print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"],"execution_count":null,"outputs":[]}]}