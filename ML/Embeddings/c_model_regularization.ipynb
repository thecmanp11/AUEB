{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Content Analytics - AUEB\n",
    "\n",
    "## Regularization Techniques + Batch Normalization\n",
    "\n",
    "* Lab Assistant: George Perakis\n",
    "* Email: gperakis[at]aeub.gr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "\n",
    "As Pavel said, **Batch Normalization is just another layer**, so you can use it as such to create your desired network architecture.\n",
    "\n",
    "The general use case is to use BN between the linear and non-linear layers in your network, because it normalizes the input to your activation function, so that you're centered in the linear section of the activation function (such as Sigmoid). \n",
    "\n",
    "On the other hand studies showed that is better to user BN after the activation function\n",
    "\n",
    "https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "# https://medium.com/@yongddeng/regression-analysis-lasso-ridge-and-elastic-net-9e65dc61d6d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# used to create mock-up data\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mock-up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.222431</td>\n",
       "      <td>-0.404840</td>\n",
       "      <td>-1.367708</td>\n",
       "      <td>-1.838549</td>\n",
       "      <td>0.558639</td>\n",
       "      <td>-1.151048</td>\n",
       "      <td>-0.326743</td>\n",
       "      <td>-0.960207</td>\n",
       "      <td>-0.245035</td>\n",
       "      <td>0.891759</td>\n",
       "      <td>-0.932901</td>\n",
       "      <td>-1.555012</td>\n",
       "      <td>0.666864</td>\n",
       "      <td>0.865662</td>\n",
       "      <td>-2.020125</td>\n",
       "      <td>1.041558</td>\n",
       "      <td>-0.699981</td>\n",
       "      <td>-0.506071</td>\n",
       "      <td>-1.436334</td>\n",
       "      <td>-0.007326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.561517</td>\n",
       "      <td>-0.242772</td>\n",
       "      <td>0.111870</td>\n",
       "      <td>-1.382386</td>\n",
       "      <td>-0.933188</td>\n",
       "      <td>0.660977</td>\n",
       "      <td>-0.452380</td>\n",
       "      <td>1.188288</td>\n",
       "      <td>1.065032</td>\n",
       "      <td>-0.412277</td>\n",
       "      <td>-0.193847</td>\n",
       "      <td>0.070784</td>\n",
       "      <td>0.054065</td>\n",
       "      <td>-0.278493</td>\n",
       "      <td>1.324269</td>\n",
       "      <td>0.159381</td>\n",
       "      <td>0.139007</td>\n",
       "      <td>0.107552</td>\n",
       "      <td>-1.656939</td>\n",
       "      <td>0.042009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878567</td>\n",
       "      <td>0.384237</td>\n",
       "      <td>0.561682</td>\n",
       "      <td>1.140172</td>\n",
       "      <td>1.130895</td>\n",
       "      <td>-1.254897</td>\n",
       "      <td>0.600579</td>\n",
       "      <td>-1.275912</td>\n",
       "      <td>-0.601391</td>\n",
       "      <td>0.230967</td>\n",
       "      <td>0.361643</td>\n",
       "      <td>-2.221348</td>\n",
       "      <td>0.877128</td>\n",
       "      <td>-0.495148</td>\n",
       "      <td>1.822775</td>\n",
       "      <td>1.104424</td>\n",
       "      <td>-1.947562</td>\n",
       "      <td>0.957133</td>\n",
       "      <td>0.697781</td>\n",
       "      <td>0.456173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.316571</td>\n",
       "      <td>-0.587674</td>\n",
       "      <td>-0.568607</td>\n",
       "      <td>0.490163</td>\n",
       "      <td>1.058316</td>\n",
       "      <td>0.838888</td>\n",
       "      <td>-0.879359</td>\n",
       "      <td>1.184195</td>\n",
       "      <td>-0.911086</td>\n",
       "      <td>-0.824618</td>\n",
       "      <td>-0.016187</td>\n",
       "      <td>0.988806</td>\n",
       "      <td>1.195091</td>\n",
       "      <td>-0.058505</td>\n",
       "      <td>0.275869</td>\n",
       "      <td>0.248299</td>\n",
       "      <td>1.487205</td>\n",
       "      <td>0.638569</td>\n",
       "      <td>-0.579259</td>\n",
       "      <td>0.316917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.946009</td>\n",
       "      <td>-0.631675</td>\n",
       "      <td>1.020665</td>\n",
       "      <td>-1.913442</td>\n",
       "      <td>-0.588241</td>\n",
       "      <td>0.069347</td>\n",
       "      <td>0.495116</td>\n",
       "      <td>0.128003</td>\n",
       "      <td>0.624314</td>\n",
       "      <td>-0.041611</td>\n",
       "      <td>-0.909590</td>\n",
       "      <td>-0.859718</td>\n",
       "      <td>-1.761045</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.416346</td>\n",
       "      <td>0.411292</td>\n",
       "      <td>0.268107</td>\n",
       "      <td>-1.060414</td>\n",
       "      <td>-0.466921</td>\n",
       "      <td>0.551149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -2.222431 -0.404840 -1.367708 -1.838549  0.558639 -1.151048 -0.326743   \n",
       "1  2.561517 -0.242772  0.111870 -1.382386 -0.933188  0.660977 -0.452380   \n",
       "2  0.878567  0.384237  0.561682  1.140172  1.130895 -1.254897  0.600579   \n",
       "3 -0.316571 -0.587674 -0.568607  0.490163  1.058316  0.838888 -0.879359   \n",
       "4  1.946009 -0.631675  1.020665 -1.913442 -0.588241  0.069347  0.495116   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.960207 -0.245035  0.891759 -0.932901 -1.555012  0.666864  0.865662   \n",
       "1  1.188288  1.065032 -0.412277 -0.193847  0.070784  0.054065 -0.278493   \n",
       "2 -1.275912 -0.601391  0.230967  0.361643 -2.221348  0.877128 -0.495148   \n",
       "3  1.184195 -0.911086 -0.824618 -0.016187  0.988806  1.195091 -0.058505   \n",
       "4  0.128003  0.624314 -0.041611 -0.909590 -0.859718 -1.761045  0.006684   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0 -2.020125  1.041558 -0.699981 -0.506071 -1.436334 -0.007326  \n",
       "1  1.324269  0.159381  0.139007  0.107552 -1.656939  0.042009  \n",
       "2  1.822775  1.104424 -1.947562  0.957133  0.697781  0.456173  \n",
       "3  0.275869  0.248299  1.487205  0.638569 -0.579259  0.316917  \n",
       "4  0.416346  0.411292  0.268107 -1.060414 -0.466921  0.551149  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feats = 20\n",
    "\n",
    "X, y = make_classification(n_samples=100_000,\n",
    "                           n_features=20,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=0,\n",
    "                           n_classes=2,\n",
    "                           n_clusters_per_class=2)\n",
    "\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# we can think of this chunk as the input layer\n",
    "model.add(Dense(128, input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# we can think of this chunk as the hidden layer    \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# we can think of this chunk as the output layer\n",
    "model.add(Dense(1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# setting up the optimization of our weights \n",
    "sgd = SGD(lr=0.1,\n",
    "          decay=1e-6,\n",
    "          momentum=0.9,\n",
    "          nesterov=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 11,781\n",
      "Trainable params: 11,395\n",
      "Non-trainable params: 386\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3750/3750 - 22s - loss: 0.4437 - acc: 0.7969 - val_loss: 0.2911 - val_acc: 0.8841\n",
      "Epoch 2/20\n",
      "3750/3750 - 21s - loss: 0.4010 - acc: 0.8248 - val_loss: 0.2696 - val_acc: 0.8949\n",
      "Epoch 3/20\n",
      "3750/3750 - 22s - loss: 0.3865 - acc: 0.8316 - val_loss: 0.2524 - val_acc: 0.9127\n",
      "Epoch 4/20\n",
      "3750/3750 - 20s - loss: 0.3757 - acc: 0.8388 - val_loss: 0.2415 - val_acc: 0.9105\n",
      "Epoch 5/20\n",
      "3750/3750 - 21s - loss: 0.3718 - acc: 0.8388 - val_loss: 0.2431 - val_acc: 0.9120\n",
      "Epoch 6/20\n",
      "3750/3750 - 19s - loss: 0.3705 - acc: 0.8423 - val_loss: 0.2557 - val_acc: 0.9151\n",
      "Epoch 7/20\n",
      "3750/3750 - 19s - loss: 0.3712 - acc: 0.8417 - val_loss: 0.2430 - val_acc: 0.9117\n",
      "Epoch 8/20\n",
      "3750/3750 - 19s - loss: 0.3694 - acc: 0.8434 - val_loss: 0.2329 - val_acc: 0.9157\n",
      "Epoch 9/20\n",
      "3750/3750 - 20s - loss: 0.3662 - acc: 0.8429 - val_loss: 0.2455 - val_acc: 0.9079\n",
      "Epoch 10/20\n",
      "3750/3750 - 20s - loss: 0.3709 - acc: 0.8409 - val_loss: 0.2575 - val_acc: 0.9074\n",
      "Epoch 11/20\n",
      "3750/3750 - 20s - loss: 0.3632 - acc: 0.8453 - val_loss: 0.2379 - val_acc: 0.9197\n",
      "Epoch 12/20\n",
      "3750/3750 - 20s - loss: 0.3648 - acc: 0.8453 - val_loss: 0.2335 - val_acc: 0.9192\n",
      "Epoch 13/20\n",
      "3750/3750 - 19s - loss: 0.3612 - acc: 0.8467 - val_loss: 0.2240 - val_acc: 0.9175\n",
      "Epoch 14/20\n",
      "3750/3750 - 20s - loss: 0.3614 - acc: 0.8465 - val_loss: 0.2255 - val_acc: 0.9179\n",
      "Epoch 15/20\n",
      "3750/3750 - 19s - loss: 0.3626 - acc: 0.8460 - val_loss: 0.2496 - val_acc: 0.9213\n",
      "Epoch 16/20\n",
      "3750/3750 - 20s - loss: 0.3597 - acc: 0.8474 - val_loss: 0.2292 - val_acc: 0.9214\n",
      "Epoch 17/20\n",
      "3750/3750 - 20s - loss: 0.3632 - acc: 0.8475 - val_loss: 0.2428 - val_acc: 0.9185\n",
      "Epoch 18/20\n",
      "3750/3750 - 20s - loss: 0.3610 - acc: 0.8478 - val_loss: 0.2288 - val_acc: 0.9168\n",
      "Epoch 19/20\n",
      "3750/3750 - 19s - loss: 0.3589 - acc: 0.8482 - val_loss: 0.2340 - val_acc: 0.9171\n",
      "Epoch 20/20\n",
      "3750/3750 - 20s - loss: 0.3588 - acc: 0.8487 - val_loss: 0.2288 - val_acc: 0.9226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cf101bd588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model on the data\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=20,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2, \n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great article in Regularization Techniques:\n",
    "# https://theaisummer.com/regularization/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
