{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Content Analytics - AUEB\n",
    "\n",
    "## Evaluation metrics and plots\n",
    "\n",
    "* Lab Assistant: George Perakis\n",
    "* Email: gperakis[at]aeub.gr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import interp\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that we will use to evaluate the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def build_binary_model(n_features: int = 20):\n",
    "    \"\"\"\n",
    "\n",
    "    :param n_features:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=n_features, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_multi_class_model(n_features: int = 20,\n",
    "                            nb_classes: int = 3) -> Sequential:\n",
    "    \"\"\"\n",
    "\n",
    "    :param n_features:\n",
    "    :param nb_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(20, input_dim=n_features, activation='relu'))\n",
    "\n",
    "    model.add(Dense(40, activation='relu'))\n",
    "\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_multi_class_roc_auc_curves(nb_classes, y_true, y_pred_score, lw: int = 2):\n",
    "    \"\"\"\n",
    "    ROC, AUC for a categorical classifier\n",
    "    \n",
    "    ROC curve extends to problems with three or more classes with what is known as the one-vs-all approach.\n",
    "    For instance, if we have three classes, we will create three ROC curves,\n",
    "\n",
    "    For each class, we take it as the positive class and group the rest classes jointly as the negative class.\n",
    "\n",
    "    Class 1 vs classes 2&3\n",
    "    Class 2 vs classes 1&3\n",
    "    Class 3 vs classes 1&2\n",
    "\n",
    "    :param nb_classes:\n",
    "    :param y_true:\n",
    "    :param y_pred_score:\n",
    "    :param lw:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(nb_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred_score[:, i])\n",
    "\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred_score.ravel())\n",
    "\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(nb_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "    for i in range(nb_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= nb_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(1)\n",
    "    plt.plot(fpr[\"micro\"],\n",
    "             tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink',\n",
    "             linestyle=':',\n",
    "             linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"],\n",
    "             tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"]),\n",
    "             color='navy',\n",
    "             linestyle=':',\n",
    "             linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua',\n",
    "                    'darkorange',\n",
    "                    'cornflowerblue'])\n",
    "\n",
    "    for i, color in zip(range(nb_classes), colors):\n",
    "        plt.plot(fpr[i],\n",
    "                 tpr[i],\n",
    "                 color=color,\n",
    "                 lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1],\n",
    "             [0, 1],\n",
    "             'k--',\n",
    "             lw=lw)\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Zoom in view of the upper left corner.\n",
    "    plt.figure(2)\n",
    "    plt.xlim(0, 0.2)\n",
    "    plt.ylim(0.7, 1)\n",
    "\n",
    "    plt.plot(fpr[\"micro\"],\n",
    "             tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink',\n",
    "             linestyle=':',\n",
    "             linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"],\n",
    "             tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"]),\n",
    "             color='navy',\n",
    "             linestyle=':',\n",
    "             linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua',\n",
    "                    'darkorange',\n",
    "                    'cornflowerblue'])\n",
    "\n",
    "    for i, color in zip(range(nb_classes), colors):\n",
    "        plt.plot(fpr[i],\n",
    "                 tpr[i],\n",
    "                 color=color,\n",
    "                 lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1],\n",
    "             [0, 1],\n",
    "             'k--', lw=lw)\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_binary_class_row_auc(y_true,\n",
    "                              clf_names: list,\n",
    "                              clfs_preds: list):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y_true: The true labels in one hot encoding\n",
    "    :param clf_names: The names of the classifiers in order to plot\n",
    "    :param clfs_preds: A list of numpy arrays, that contain predictions from various classifiers\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert len(clf_names) == len(clfs_preds)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    for clf_name, preds in zip(clf_names, clfs_preds):\n",
    "        fpr, tpr, thresholds = roc_curve(y_true,\n",
    "                                         preds)\n",
    "\n",
    "        # AUC value can also be calculated like this.\n",
    "\n",
    "        auc_score = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr,\n",
    "                 tpr,\n",
    "                 label='{} (area = {:.3f})'.format(clf_name, auc_score))\n",
    "\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # Zoom in view of the upper left corner.\n",
    "    plt.figure(2)\n",
    "    plt.xlim(0, 0.2)\n",
    "    plt.ylim(0.7, 1)\n",
    "    plt.plot([0, 1],\n",
    "             [0, 1],\n",
    "             'k--')\n",
    "\n",
    "    for clf_name, preds in zip(clf_names, clfs_preds):\n",
    "        fpr, tpr, thresholds = roc_curve(y_true,\n",
    "                                         preds)\n",
    "\n",
    "        # AUC value can also be calculated like this.\n",
    "\n",
    "        auc_score = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr,\n",
    "                 tpr,\n",
    "                 label='{} (area = {:.3f})'.format(clf_name, auc_score))\n",
    "\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve (zoomed in at top left)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(y_true,\n",
    "                           y_pred,\n",
    "                           class_names: List[str],\n",
    "                           figsize: Tuple[int, int] = (10, 7),\n",
    "                           fontsize: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heat-map.\n",
    "\n",
    "    For something more extraordinary check this repo:\n",
    "    https://github.com/wcipriano/pretty-print-confusion-matrix\n",
    "\n",
    "\n",
    "    :param class_names:  An ordered list of class names\n",
    "    :param figsize: A 2-long tuple, the first value determining the horizontal size of the outputted\n",
    "                    figure, the second determining the vertical size. Defaults to (10,7).\n",
    "    :param fontsize: Font size for axes labels. Defaults to 14.\n",
    "    :return: The confusion matrix as a dataset\n",
    "    \"\"\"\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "    except ValueError:\n",
    "\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(),\n",
    "                                 rotation=0,\n",
    "                                 ha='right',\n",
    "                                 fontsize=fontsize)\n",
    "\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(),\n",
    "                                 rotation=45,\n",
    "                                 ha='right',\n",
    "                                 fontsize=fontsize)\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    return df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_binary_example():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    X, y = make_classification(n_samples=100_000)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    keras_model = build_binary_model()\n",
    "\n",
    "    print('Fitting Keras Binary Model')\n",
    "    keras_model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=128,\n",
    "                    verbose=2)\n",
    "\n",
    "    y_pred_keras = keras_model.predict(X_test).ravel()\n",
    "\n",
    "    print('Fitting Random Forests CLF')\n",
    "    # Supervised transformation based on random forests\n",
    "    rf = RandomForestClassifier(max_depth=3,\n",
    "                                n_estimators=50)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print('Fitting Logistic Regression CLF')\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_lr = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    plot_binary_class_row_auc(y_true=y_test,\n",
    "                              clf_names=['MLP (Feed Forward)',\n",
    "                                         'RandomF',\n",
    "                                         'LogisticR'],\n",
    "                              clfs_preds=[y_pred_keras,\n",
    "                                          y_pred_rf,\n",
    "                                          y_pred_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_multi_class_example():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 3 classes to classify\n",
    "    n_classes = 3\n",
    "\n",
    "    X, y = make_classification(n_samples=100_000,\n",
    "                               n_features=20,\n",
    "                               n_informative=3,\n",
    "                               n_redundant=0,\n",
    "                               n_classes=n_classes,\n",
    "                               n_clusters_per_class=2)\n",
    "\n",
    "    # Binarize the output\n",
    "    lb = LabelBinarizer()\n",
    "\n",
    "    y_hot = lb.fit_transform(y)\n",
    "\n",
    "    n_classes = y_hot.shape[1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_hot, test_size=0.25)\n",
    "\n",
    "    keras_model2 = build_multi_class_model()\n",
    "\n",
    "    keras_model2.fit(X_train,\n",
    "                     y_train,\n",
    "                     epochs=20,\n",
    "                     batch_size=128,\n",
    "                     verbose=2)\n",
    "\n",
    "    y_score = keras_model2.predict(X_test)\n",
    "\n",
    "    plot_multi_class_roc_auc_curves(nb_classes=n_classes,\n",
    "                                    y_true=y_test,\n",
    "                                    y_pred_score=y_score)\n",
    "\n",
    "    y_pred_class = keras_model2.predict_classes(X_test)\n",
    "\n",
    "    y_test_normal = lb.inverse_transform(y_test)\n",
    "\n",
    "    print_confusion_matrix(y_true=y_test_normal,\n",
    "                           y_pred=y_pred_class,\n",
    "                           class_names=['0', '1', '2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Mock-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Binary Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 20\n",
    "\n",
    "X, y = make_classification(n_samples=100_000,\n",
    "                           n_features=20,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=0,\n",
    "                           n_classes=2,\n",
    "                           n_clusters_per_class=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of Feed Forward Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_dim=n_feats, activation='relu'))\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Fitting Keras Binary Model')\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=15,\n",
    "          batch_size=128,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = model.predict(X_test)\n",
    "print('shape: {}'.format(y_pred_keras.shape))\n",
    "y_pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = y_pred_keras.ravel()\n",
    "print('shape: {}'.format(y_pred_keras.shape))\n",
    "y_pred_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a Random Forests Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fitting Random Forests CLF')\n",
    "# Supervised transformation based on random forests\n",
    "rf = RandomForestClassifier(max_depth=3, n_estimators=50)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fitting Logistic Regression CLF')\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Binary ROC curve for all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_binary_class_row_auc(y_true=y_test,\n",
    "                          clf_names=['Keras',\n",
    "                                     'RandomF',\n",
    "                                     'LogisticR'],\n",
    "                          clfs_preds=[y_pred_keras,\n",
    "                                      y_pred_rf,\n",
    "                                      y_pred_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Mock-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 classes to classify\n",
    "n_classes = 5\n",
    "n_feats = 20\n",
    "\n",
    "X, y = make_classification(n_samples=100_000,\n",
    "                           n_features=n_feats,\n",
    "                           n_informative=5,\n",
    "                           n_redundant=0,\n",
    "                           n_classes=n_classes,\n",
    "                           n_clusters_per_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using OneHotEncoder you may also use LabelBinarizer()\n",
    "# Binarize the output\n",
    "lb = LabelBinarizer()\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hot = lb.fit_transform(y)\n",
    "y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = y_hot.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y_hot,\n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of Multi-class Feed Forward Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(20, input_dim=n_feats, activation='relu'))\n",
    "\n",
    "model2.add(Dense(40, activation='relu'))\n",
    "\n",
    "model2.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train,\n",
    "           y_train,\n",
    "           epochs=30,\n",
    "           batch_size=256,\n",
    "           verbose=2,\n",
    "           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_multi_class_roc_auc_curves(nb_classes=n_classes,\n",
    "                                y_true=y_test,\n",
    "                                y_pred_score=y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = np.argmax(model2.predict(X_test), axis=-1)\n",
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_normal = lb.inverse_transform(y_test)\n",
    "y_test_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(y_true=y_test_normal,\n",
    "                       y_pred=y_pred_class,\n",
    "                       class_names=range(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_normal, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
